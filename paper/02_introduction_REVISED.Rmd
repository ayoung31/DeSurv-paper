<!-- REVISED INTRODUCTION â€” prediction-validation structure for PNAS -->
<!-- New citation keys needed in references_30102025.bib: -->
<!--   cook2007fisher, bair2006supervised, aran2015systematic, -->
<!--   frigyesi2008nmf, arora2020survclust, damrauer2014intrinsic, -->
<!--   tishby1999information, chapelle2006semi -->
<!-- Existing keys used: lee1999learning, moffitt2015virtual, peng2019novo, -->
<!--   collisson2011subtypes, Bailey2016, rashid2020purity, bair2004semi, -->
<!--   brunet2004metagenes, Hoadley2018, huang2020low, le2025survnmf, -->
<!--   Schwarzova2023 -->

Predicting which patients will respond to therapy or progress rapidly requires identifying the transcriptional signatures that drive clinical outcomes [@collisson2011subtypes], yet in bulk RNA-sequencing, which currently provides the large clinically annotated cohorts required for survival modeling, the observed expression profile of each sample reflects contributions from malignant cells, cancer-associated fibroblasts, immune infiltrates, and other microenvironmental components that can obscure these signatures [@nguyen2024fourteen]. Deconvolution methods based on nonnegative matrix factorization (NMF) have been instrumental in resolving this mixture into additive, interpretable gene programs that often correspond to recognizable cell types or transcriptional states [@lee1999learning; @moffitt2015virtual; @peng2019novo]. However, the programs that explain the most transcriptomic variance are not necessarily the programs that drive clinical outcomes [@bair2004semi]. In pancreatic ductal adenocarcinoma (PDAC), for example, exocrine and tissue-composition signals dominate expression variance but contribute little to survival prediction, while lower-variance programs reflecting basal-like or activated stromal biology carry the strongest prognostic associations [@moffitt2015virtual; @rashid2020purity; @peng2024determination]. This misalignment between variance and prognosis is not unique to PDAC: tumor purity alone accounts for a large fraction of observed expression variation across cancer types, and nearly half of genes used for subtyping in glioblastoma and lung adenocarcinoma correlate with purity rather than biology [@aran2015systematic]. When unsupervised methods preferentially capture these variance-dominant signals, the resulting programs require extensive downstream filtering to identify the subset with clinical relevance, a process that is ad hoc, cohort-specific, and difficult to reproduce [@collisson2019molecular].

The standard approach to molecular subtyping proceeds in two steps: first, discover latent programs through unsupervised factorization; then, evaluate their clinical relevance through retrospective survival analysis [@brunet2004metagenes; @Bailey2016; @peng2019novo]. This paradigm has yielded important biological insights, including the identification of basal-like and classical tumor programs in PDAC [@collisson2011subtypes; @moffitt2015virtual] and compartment-specific deconvolution across 33 cancer types [@peng2019novo]. However, the two-step design creates a structural misalignment: the objective optimized during discovery (reconstruction error) differs from the criterion used during evaluation (survival association) [@cook2007fisher]. Unsupervised NMF minimizes reconstruction error subject to non-negativity, so its factors tend to be dominated by the highest-variance patterns in the data, which may reflect tissue composition, sample processing, or other outcome-neutral sources. Programs that are prognostically relevant but explain modest variance can be diluted across multiple factors or missed entirely. As a consequence, PDAC subtyping efforts spanning over a decade proposed between two and six subtypes, with finer-grained classifications showing variable cross-cohort concordance [@Schwarzova2023; @collisson2019molecular]. The field ultimately converged on a robust basal/classical dichotomy [@collisson2011subtypes; @moffitt2015virtual; @Bailey2016], but reaching this consensus required extensive retrospective evaluation across multiple independent cohorts [@rashid2020purity; @collisson2019molecular].

Whether incorporating survival information during factorization improves generalizability, or risks overfitting to cohort-specific outcome distributions, remains an open empirical question. Statistically, sufficient dimension reduction theory establishes that response-guided subspace estimation targets the directions most relevant to the outcome, whereas variance-maximizing projections (as in PCA) target different directions that may be orthogonal to the response [@cook2007fisher; @bair2006supervised]. When the outcome depends on cell populations that are compositionally minor or contribute low variance to bulk expression, unsupervised methods systematically miss these features, while outcome-supervised methods can recover them. Theory and prior empirical work support the expectation that outcome-guided methods can recover prognostically relevant structure that unsupervised approaches miss [@bair2004semi; @bair2006supervised; @arora2020survclust]. Biologically, supervision concentrates representational capacity on the programs that distinguish patients with different outcomes, effectively filtering out variance-dominant but prognostically neutral signals during learning rather than in a separate post hoc step. This reorganization has a second benefit: by reducing the effective number of outcome-relevant factors, supervision can simplify the notoriously difficult problem of rank selection in NMF. Standard rank heuristics, cophenetic correlation, silhouette width, and dispersion, frequently disagree and can overfit [@frigyesi2008nmf; @brunet2004metagenes], leaving the analyst without a principled criterion. When the objective includes a survival term, rank selection becomes a more principled, externally anchored model-selection problem: choose the rank (and other hyperparameters) that maximize cross-validated concordance with patient outcomes, providing a clinically meaningful criterion in place of heuristic diagnostics.

Here we present DeSurv, a survival-supervised deconvolution framework that integrates NMF with Cox proportional hazards modeling. The key architectural choice is where survival supervision enters the factorization. In DeSurv, factor scores are defined as linear projections of the expression data onto the gene program matrix: $Z = W^\top X$. The Cox partial likelihood is then a function of $W$ and the associated regression coefficients $\beta$, so that the survival gradient acts directly on the gene programs. Sample-level loadings $H$ are updated solely through the reconstruction objective and receive no survival gradient. This design ensures that gene programs are shaped by both reconstruction fidelity and outcome association, while sample loadings remain unconstrained, preserving the biological interpretability of the deconvolution as a mixture model. DeSurv operates as a semi-supervised method: the reconstruction loss (weight $1-\alpha$) penalizes deviation from the observed expression data, while the survival term (weight $\alpha$) directs gene programs toward outcome-relevant structure, at the cost of some reconstruction fidelity. Because $\alpha$ is selected via cross-validated concordance, values large enough to overfit to cohort-specific survival patterns are penalized by poor out-of-sample performance, preventing the survival term from overwhelming the factorization. Because the gene program matrix $W$ defines shared transcriptomic programs rather than individual sample loadings, it is not sample-specific: new samples can be scored by simple projection ($Z_{\text{new}} = W^\top X_{\text{new}}$) without requiring their survival data, a property not shared by methods that supervise through $H$ [@huang2020low; @le2025survnmf]. To address model selection, DeSurv employs Bayesian optimization [@snoek2012practical] over cross-validated concordance to jointly tune the factorization rank $k$, the supervision strength $\alpha$, and regularization parameters, replacing heuristic rank criteria with a single, outcome-driven objective; the $\alpha = 0$ endpoint recovers standard NMF as a special case.

We evaluate DeSurv in three settings that test the predictions above. First, in simulations with known latent structure and survival associations, we show that DeSurv recovers the true factorization rank and the identity of prognostic programs more reliably than standard NMF, that its advantage scales with the degree of divergence between variance and prognosis, and that it vanishes under null conditions where no survival signal exists. Second, in PDAC, we demonstrate that survival supervision reorganizes the learned factor structure: DeSurv suppresses variance-dominant but prognostically neutral signals (e.g., exocrine content) and concentrates survival association into a smaller set of biologically interpretable factors aligned with known tumor and microenvironmental programs. These survival-aligned factors generalize across independent PDAC cohorts with consistent hazard ratios and clearer survival separation than their unsupervised counterparts. Third, we show that a PDAC-trained DeSurv factor retains prognostic signal when projected into bladder cancer samples, consistent with prior reports that basal-like transcriptional structure generalizes across epithelial cancers [@damrauer2014intrinsic; @Hoadley2018].
