<!-- REVISED METHODS â€” semi-supervised framing, W-vs-H distinction, out-of-sample statement -->
<!-- Changes from 03_methods.Rmd: -->
<!--   1. Semi-supervised framing added to model description -->
<!--   2. W-vs-H supervision distinction stated explicitly -->
<!--   3. Out-of-sample statement clarified (nested CV, no data leakage) -->
<!--   4. Minor language tightening throughout -->

## Problem formulation and notation
Let $X \in \mathbb{R}^{p \times n}_{\ge 0}$ denote the nonnegative gene expression matrix. DeSurv approximates $X \approx WH$, where $W \in \mathbb{R}^{p\times k}_{\ge0}$ contains nonnegative gene programs and $H \in \mathbb{R}^{k\times n}_{\ge0}$ contains sample loadings. Additionally, let $y \in \mathbb{R}^{n}_{>0}$ denote patient survival times, $\delta \in \{0,1\}^{n}$ the censoring indicators ($\delta_i = 1$ if the event is observed), and $\beta \in \mathbb{R}^{k}$ the Cox regression coefficients. Survival outcomes are modeled through a Cox proportional hazards model with factor scores $Z = W^\top X \in \mathbb{R}^{k \times n}$ and linear predictor $Z^\top \beta$.

## The DeSurv Model
DeSurv integrates Nonnegative Matrix Factorization (NMF) with penalized Cox regression to identify gene programs associated with patient survival. The method operates in a semi-supervised framework: the reconstruction loss penalizes deviation from the observed expression data, while the survival term directs gene programs toward outcome-relevant structure. The parameter $\alpha \in [0,1]$ controls the relative contribution of each objective.

The joint objective is
\begin{equation}
\label{eqn:desurv}
\mathcal{L}(W,H,\beta) =
(1-\alpha)\,\mathcal{L}_{\mathrm{NMF}}(W,H)
- \alpha\,\mathcal{L}_{\mathrm{Cox}}(W,\beta),
\end{equation}
where $\mathcal{L}_{\mathrm{NMF}}(W,H)$ is the NMF reconstruction error and $\mathcal{L}_{\mathrm{Cox}}(W,\beta)$ is the elastic-net penalized partial log-likelihood. A critical architectural choice is where survival supervision enters the factorization. Because factor scores are defined as $Z = W^\top X$, the Cox partial likelihood $\mathcal{L}_{\mathrm{Cox}}$ is a direct function of $W$ and $\beta$, and the survival gradient acts explicitly on the gene program matrix $W$. The sample-level loadings $H$ enter only through the reconstruction term and receive no survival gradient, preserving their interpretation as mixture coefficients [@lee1999learning; @gaujoux2010flexible]. When $\alpha = 0$, DeSurv reduces to standard unsupervised NMF. The Cox component also accommodates additional sample-level covariates (e.g., tumor stage or grade) alongside $Z$, enabling adjustment for known prognostic factors during optimization.

Optimization proceeds by alternating updates for $H$, $W$, and $\beta$, using multiplicative rules for $H$ [@lee1999learning], projected gradients for $W$, and coordinate descent for $\beta$. Although non-convex, these updates are shown to converge to a stationary point under mild conditions (SI Appendix). Complete derivations and algorithmic details are provided in the SI Appendix.

## Hyperparameter selection and cross-validation
Hyperparameters $(k,\alpha,\lambda_H,\lambda,\xi)$ were selected by maximizing the cross-validated C-index using Bayesian optimization, with final rank $k$ chosen by the one-standard-error rule (the smallest $k$ whose predicted performance lay within one standard error of the maximum). All model selection was performed entirely within training data using nested cross-validation; no validation cohort data were used during any stage of tuning. Because $\alpha$ is selected via cross-validated concordance, values large enough to overfit to cohort-specific survival patterns are penalized by poor out-of-sample performance, preventing the survival term from overwhelming the factorization. Each fold was trained using multiple random initializations, and fold-level performance was defined as the average C-index across initializations. For stability, we used a consensus-based initialization for the final model, aggregating multiple DeSurv runs into a gene-gene co-occurrence matrix and constructing an initialization $W_0$ from the resulting clusters (SI Appendix). Before validation, each column of $W$ was truncated to its BO-selected number of top genes (details in SI Appendix), denoted $\tilde{W}$.

External validation was performed by projecting new datasets onto the learned programs via $Z = \tilde{W}^\top X_{\text{new}}$ and evaluating survival associations using C-index and log-rank statistics. Because the learned $W$ is fixed at training time and validation samples are scored by simple projection, no retraining or access to validation survival data is required. Reported external hazard ratios and log-rank statistics therefore reflect purely out-of-sample generalization. To evaluate the quality of DeSurv-derived gene signatures for subtyping, new datasets $X_{\text{new}}$ were clustered on genes in $\tilde{W}$, and survival differences were analyzed for the derived clusters. Further training, validation, and runtime details appear in the SI Appendix.


## Simulation studies
Simulation studies were conducted to assess recovery of prognostic latent structure and survival prediction under controlled conditions. Gene expression data were generated from a nonnegative factor model $X=WH$, where gene loadings $W$ comprised three gene classes: marker genes, background genes, and noise genes. Marker genes were simulated to load strongly on a single factor and weakly on others, background genes to load strongly across all factors, and noise genes to have uniformly low loadings; each class was generated from a distinct gamma distribution. Sample-level factor activities $H$ were generated from a gamma distribution.

Survival times were generated from an exponential distribution in which risk depended on marker gene expression through $X^T\tilde{W}$, where $\tilde{W}$ retained marker gene loadings for their corresponding factors and was zero otherwise; censoring times were generated independently from an exponential distribution. Each dataset was analyzed using DeSurv and standard NMF followed by Cox regression on inferred factors, both tuned using cross-validated concordance index via Bayesian optimization. Performance was summarized across repeated simulation replicates. We considered three simulation scenarios: a primary scenario where prognostic programs explain low variance relative to outcome-neutral signals, a null scenario with no survival signal, and a mixed scenario where prognostic and variance-dominant programs partially overlap.

## Real-world datasets
We analyzed publicly available RNA-seq and microarray cohorts of pancreatic ductal adenocarcinoma (PDAC) and bladder cancer with corresponding overall survival outcomes. Gene expression matrices were converted to TPM, log-transformed, and filtered to remove low-expression genes. Survival times and censoring indicators were taken from the associated clinical annotations. Of the seven PDAC cohorts we considered, two were used for training (TCGA and CPTAC) and the rest were used for external validation (Dijk, Moffitt, PACA, Puleo). The bladder cohort was split into training and validation cohorts via a 70/30 split. To harmonize differences in scale across cohorts, filtered gene expression data was within-subject rank transformed before model training. More details about the datasets can be found in the SI Appendix.

## Software and availability
An R package implementing DeSurv is available at github.com/ayoung31/DeSurv. Code and processed data used in this study are available at github.com/ayoung31/DeSurv-paper.
